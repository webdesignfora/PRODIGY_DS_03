# -*- coding: utf-8 -*-
"""Prodigy_Infotech_DS_Task-03.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1OskMuGkW8bsK1T3eriftvVeccbyfpu4j

# Prodigy Infotech

Author: Aarti Wani

Data Science Intern

Task-03

Task: Build a decision tree classifier to predict whether a customer will purchase a product or service based on their demographic and behavioral data. Use a dataset such as the Bank Marketing dataset from the UCI Machine Learning Repository.
"""

# Importing the libraries
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn import metrics
from sklearn.preprocessing import LabelEncoder

# Loading data
data=pd.read_csv('bank.csv')
columns=data.columns
data.head()

# Checking dimensions
data.shape

# Checking the datatypes of features
data.info()

# Checking five variable summary of numerical features
data.describe()

# class distribution
data['deposit'].value_counts()

# Missing values identification
data.isna().sum()

# Checking no. of unique values in each feature
data.nunique()

# duplicate values
data.duplicated().sum()

# Checking distribution of age feature
sns.distplot(x=data['age'])

# Checking distribution of balance feature
sns.distplot(x=data['balance'])

# Checking distribution of duration feature
sns.distplot(x=data['duration'])

# outlier detection & removal
continuous_data=data.select_dtypes(include='int64')
for col in continuous_data:
  sns.boxplot(x=col,data=data)
  plt.show()

for column in continuous_data:
  q1=data[column].quantile(0.25)
  q3=data[column].quantile(0.75)
  IQR=q3-q1
  l_limit=q1-(IQR*1.5)
  u_limit=q3+(IQR*1.5)
  data.loc[data[column]<l_limit,column]=l_limit
  data.loc[data[column]>u_limit,column]=u_limit

continuous_data=data.select_dtypes(include='int64')
for col in continuous_data:
  sns.boxplot(x=col,data=data)
  plt.show()

# Encoding the categorical value
categorical_data=data.select_dtypes(include='object')
for col in categorical_data:
  le=LabelEncoder()
  data[col]=le.fit_transform(data[col])
data.head()

# separating the data into input and output features
X=data.drop('deposit',axis=1)
y=data['deposit']

# scaling the input features
from sklearn.preprocessing import MinMaxScaler
sc=MinMaxScaler()
X=sc.fit_transform(X)

# feature selection
from sklearn.feature_selection import SelectKBest,chi2
selector=SelectKBest(chi2,k=10)
selector.fit(X,y)
X=selector.transform(X)
selector.get_support()

feature_names=['default','balance','housing','loan','contact','duration','campaign','pdays','previous','poutcome']
labels=np.array(y.unique()).astype('str').tolist()

# Split dataset for training and testing
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=1)

# Building the dec decision tree model
dt=tree.DecisionTreeClassifier(max_depth=3)
clf=dt.fit(X_train,y_train)
# Making predictions
y_pred=dt.predict(X_test)
y_pred

# Evaluating the model
print('accuracy_score:',metrics.accuracy_score(y_test,y_pred))
print('classification_report:',metrics.classification_report(y_test,y_pred))
print('roc-auc score:',metrics.roc_auc_score(y_test,y_pred))

plt.figure(figsize=(30,20))
tree.plot_tree(clf, feature_names=feature_names,class_names=labels ,rounded = True, filled=True, fontsize=14)
plt.show()